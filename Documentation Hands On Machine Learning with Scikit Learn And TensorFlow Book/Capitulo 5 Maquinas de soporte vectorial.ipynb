{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGB3OKb9llvxRfpjX1mLUT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Máquinas de vectores de soporte\n","\n","Una máquina de vectores de soporte (SVM) es un modelo de aprendizaje automático muy potente y versátil, capaz de realizar clasificación lineal o no lineal, regresión e incluso detección de valores atípicos. Es uno de los modelos más populares en Machine Learning, y cualquier persona interesada en Machine Learning debería tenerlo en su caja de herramientas. Las SVM son particularmente adecuadas para la clasificación de conjuntos de datos complejos pero de tamaño pequeño o mediano.\n","Este capítulo explicará los conceptos básicos de las SVM, cómo usarlas y cómo funcionan.\n"],"metadata":{"id":"hT_Ps6KjxeAh"}},{"cell_type":"markdown","source":["## Clasificación SVM lineal\n","\n","La idea fundamental detrás de las SVM se explica mejor con algunas imágenes. La Figura 5-1 muestra parte del conjunto de datos del iris que se introdujo al final del Capítulo 4. Las dos clases se pueden separar fácilmente con una línea recta (son linealmente separables). El gráfico de la izquierda muestra los límites de decisión de tres posibles clasificadores lineales. El modelo cuyo límite de decisión está representado por la línea discontinua es tan malo que ni siquiera separa las clases correctamente. Los otros dos modelos funcionan perfectamente en este conjunto de entrenamiento, pero sus límites de decisión se acercan tanto a las instancias que estos modelos probablemente no funcionarán tan bien en nuevas instancias. Por el contrario, la línea continua en el gráfico de la derecha representa el límite de decisión de un clasificador SVM; esta línea no solo separa las dos clases, sino que también se mantiene lo más alejada posible de las instancias de capacitación más cercanas. Puede pensar en un clasificador SVM como si encajara en la calle 155 más ancha posible (representada por las líneas discontinuas paralelas) entre las clases. Esto se llama clasificación de gran margen.\n","\n","![SVM LMC](https://github.com/DataEngel/Training-and-studying-Machine-Learning/assets/63415652/581be30e-c229-4ac6-ab64-247736c6754a)\n"],"metadata":{"id":"XEtEmH8MdOKw"}},{"cell_type":"markdown","source":["Tenga en cuenta que agregar más instancias de capacitación \"fuera de la calle\" no afectará en absoluto el límite de decisión: está completamente determinado (o \"respaldado\") por las instancias ubicadas en el borde de la calle. Estos casos se denominan vectores de soporte (están encerrados en un círculo en la figura 5-1).\n","\n","Nota: las SVM son sensibles a las escalas de características, como puede ver en la Figura 5-2: en el diagrama de la izquierda, la escala vertical es mucho más grande que la escala horizontal, por lo que la calle más ancha posible está cerca de la horizontal. Después de escalar características (p. ej., usando StandardScaler de Scikit-Learn), el límite de decisión se ve mucho mejor (en el gráfico de la derecha).\n","\n","![SVM SFS](https://github.com/DataEngel/Training-and-studying-Machine-Learning/assets/63415652/011d8524-1f25-49fd-a87e-001015a3d743)\n"],"metadata":{"id":"jdlL2n-fdONJ"}},{"cell_type":"markdown","source":["## Clasificación de margen suave\n","\n","Si imponemos estrictamente que todas las instancias estén fuera de la calle y en el lado derecho, esto se denomina clasificación de margen duro. Hay dos problemas principales con la clasificación de margen duro. En primer lugar, solo funciona si los datos son linealmente separables y, en segundo lugar, es bastante sensible a los valores atípicos. La Figura 5-3 muestra el conjunto de datos del iris con solo un valor atípico adicional: a la izquierda, es imposible encontrar un margen duro y, a la derecha, el límite de decisión termina siendo muy diferente al que vimos en la Figura 5-1 sin el atípico, y probablemente no se generalice tan bien.\n","\n","![Screenshot 2023-06-06 233300](https://github.com/DataEngel/Training-and-studying-Machine-Learning/assets/63415652/b140402e-754a-4e94-a987-e70a80ab55b7)\n"],"metadata":{"id":"pSpHwJaBdOPv"}},{"cell_type":"markdown","source":["Para evitar estos problemas, es preferible utilizar un modelo más flexible. El objetivo es encontrar un buen equilibrio entre mantener la calle lo más grande posible y limitar las violaciones de los márgenes (es decir, instancias que terminan en el medio de la calle o incluso en el lado equivocado). Esto se llama clasificación de margen blando.\n","\n","En las clases SVM de Scikit-Learn, puede controlar este equilibrio utilizando el hiperparámetro C: un valor C más pequeño conduce a una calle más ancha pero a más violaciones de margen. La Figura 5-4 muestra los límites de decisión y los márgenes de dos clasificadores SVM de margen suave en un conjunto de datos separable no linealmente. A la izquierda, usando un valor C bajo, el margen es bastante grande, pero muchas instancias terminan en la calle. A la derecha, usando un valor C alto, el clasificador comete menos violaciones de margen pero termina con un margen más pequeño. Sin embargo, parece probable que el primer clasificador generalice mejor: de hecho, incluso en este conjunto de entrenamiento comete menos errores de predicción, ya que la mayoría de las violaciones de margen están en realidad en el lado correcto del límite de decisión.\n","\n","![2](https://github.com/DataEngel/Training-and-studying-Machine-Learning/assets/63415652/d575aa0a-7b99-4345-9609-9ade2ff7199d)\n"],"metadata":{"id":"JjCDn0y9dOSQ"}},{"cell_type":"markdown","source":["Para evitar estos problemas, es preferible utilizar un modelo más flexible. El objetivo es encontrar un buen equilibrio entre mantener la calle lo más grande posible y limitar las violaciones de los márgenes (es decir, instancias que terminan en el medio de la calle o incluso en el lado equivocado). Esto se llama clasificación de margen suave.\n","\n","En las clases SVM de Scikit-Learn, puede controlar este equilibrio utilizando el hiperparámetro C: un valor C más pequeño conduce a una calle más ancha pero a más violaciones de margen. La Figura 5-4 muestra los límites de decisión y los márgenes de dos clasificadores SVM de margen suave en un conjunto de datos separable no linealmente. A la izquierda, usando un valor C bajo, el margen es bastante grande, pero muchas instancias terminan en la calle. A la derecha, usando un valor C alto, el clasificador comete menos violaciones de margen pero termina con un margen más pequeño. Sin embargo, parece probable que el primer clasificador generalice mejor: de hecho, incluso en este conjunto de entrenamiento comete menos errores de predicción, ya que la mayoría de las violaciones del margen están en realidad en el lado correcto del límite de decisión.\n","\n","![1](https://github.com/DataEngel/Training-and-studying-Machine-Learning/assets/63415652/313e206f-9a75-4c7e-8bee-d5d1093799c5)\n"],"metadata":{"id":"dEmjDHCldOUo"}},{"cell_type":"markdown","source":["Si su modelo SVM está sobreajustado, puede intentar regularizarlo reduciendo C.\n","\n","El siguiente código de Scikit-Learn carga el conjunto de datos de iris, escala las características y luego entrena un modelo SVM lineal (usando la clase LinearSVC con C = 1 y la función de pérdida de bisagra, descrita en breve) para detectar flores de Iris-Virginica. El modelo resultante se representa a la izquierda de la Figura 5-4.\n"],"metadata":{"id":"00ieU2QadOXH"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import datasets\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import LinearSVC\n","iris = datasets.load_iris()\n","X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n","y = (iris[\"target\"] == 2).astype(np.float64) # Iris-Virginica\n","svm_clf = Pipeline([\n"," (\"scaler\", StandardScaler()),\n"," (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n"," ])\n","svm_clf.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"5WrThOfAT8fI","executionInfo":{"status":"ok","timestamp":1686635538916,"user_tz":360,"elapsed":1105,"user":{"displayName":"Miguel Angel Velazquez Romero","userId":"17573582378593499801"}},"outputId":"f02eb69e-9038-4913-ce51-b345a7ce6858"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('scaler', StandardScaler()),\n","                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n","                (&#x27;linear_svc&#x27;, LinearSVC(C=1, loss=&#x27;hinge&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n","                (&#x27;linear_svc&#x27;, LinearSVC(C=1, loss=&#x27;hinge&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=1, loss=&#x27;hinge&#x27;)</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["Luego, como de costumbre, puede usar el modelo para hacer predicciones:"],"metadata":{"id":"Ga_4Y2_iSi5K"}},{"cell_type":"code","source":["svm_clf.predict([[5.5, 1.7]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJZMSNaWULaD","executionInfo":{"status":"ok","timestamp":1686635594008,"user_tz":360,"elapsed":8,"user":{"displayName":"Miguel Angel Velazquez Romero","userId":"17573582378593499801"}},"outputId":"cb2a0dcc-a918-4e8a-ea43-838fc7e4c61c"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["A diferencia de los clasificadores de regresión logística, los clasificadores SVM no generan probabilidades para cada clase.\n","\n","Alternativamente, podría usar la clase SVC, usando SVC(kernel=\"linear\", C=1), pero es mucho más lento, especialmente con grandes conjuntos de entrenamiento, por lo que no se recomienda. Otra opción es usar la clase SGDClassifier, con SGDClassifier(loss=\"hinge\", alpha=1/(m*C)). Esto aplica el Descenso de Gradiente Estocástico regular (vea el Capítulo 4) para entrenar un clasificador SVM lineal. No converge tan rápido como la clase LinearSVC, pero puede ser útil para manejar grandes conjuntos de datos que no caben en la memoria (entrenamiento fuera del núcleo) o para manejar tareas de clasificación en línea.\n","\n","La clase LinearSVC regulariza el término de sesgo, por lo que primero debe centrar el conjunto de entrenamiento restando su media. Esto es automático si escala los datos usando StandardScaler. Además, asegúrese de establecer el hiperparámetro de pérdida en \"bisagra\", ya que no es el valor predeterminado. Finalmente, para un mejor rendimiento, debe establecer el hiperparámetro dual en Falso, a menos que haya más funciones que instancias de entrenamiento (hablaremos de la dualidad más adelante en este capítulo).\n"],"metadata":{"id":"73_VtdJUSi7m"}},{"cell_type":"markdown","source":[],"metadata":{"id":"GfJlQt8_Si-E"}},{"cell_type":"markdown","source":[],"metadata":{"id":"xBCleTHbSjAK"}},{"cell_type":"markdown","source":[],"metadata":{"id":"xA6QcGaSSjCn"}}]}